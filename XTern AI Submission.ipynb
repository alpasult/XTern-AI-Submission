{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "917cd7b5-bbd9-485f-b793-bd720739bc18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.26.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.24.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\administrator\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import csv\n",
    "!{sys.executable} -m pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f01f3-4544-4c49-a83d-9a580bb79f48",
   "metadata": {},
   "source": [
    "### Given the data set, do a quick exploratory data analysis to get a feel for the distributions and biases of the data.  Report any visualizations and findings used and suggest any other impactful business use cases for that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e4b5639f-5961-47c8-b077-fd058e8b0ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('XTern 2024 Artificial Intelegence Data Set - Xtern_TrainData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3b154bd7-a79f-4fd8-8dab-926658085e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv.DictReader(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3104c15c-6a8e-47ab-bafb-edecf8b8612c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 2273, 2719, 3]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years = [0, 0, 0, 0]\n",
    "for row in data:\n",
    "    match row['Year']:\n",
    "        case \"Year 1\":\n",
    "            years[0] += 1\n",
    "        case \"Year 2\":\n",
    "            years[1] += 1\n",
    "        case \"Year 3\":\n",
    "            years[2] += 1\n",
    "        case \"Year 4\":\n",
    "            years[3] += 1\n",
    "years"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b65bb8-ab63-4b77-9310-3bc0de52b384",
   "metadata": {},
   "source": [
    "Mostly year 2 and year 3 students order from FoodX. This maybe due to cheap food options being able to Year 1 students at the University food hall or perhaps the FoodX foodtruck is only near the 2nd and 3rd year dormitories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "239ccf7d-2c9c-46c2-989b-c5dcd54942be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physics 610\n",
      "Chemistry 640\n",
      "Biology 635\n",
      "Business Administration 334\n",
      "Anthropology 146\n",
      "Mathematics 582\n",
      "Economics 511\n",
      "Astronomy 619\n",
      "Marketing 239\n",
      "Political Science 309\n",
      "Finance 135\n",
      "Sociology 31\n",
      "Accounting 62\n",
      "Psychology 76\n",
      "International Business 29\n",
      "Music 21\n",
      "Mechanical Engineering 11\n",
      "Philosophy 4\n",
      "Fine Arts 3\n",
      "Civil Engineering 3\n"
     ]
    }
   ],
   "source": [
    "file.seek(0)\n",
    "majors = []\n",
    "majorsNum = []\n",
    "for row in data:\n",
    "    if not (row['Major'] in majors):\n",
    "        majors.append(row['Major'])\n",
    "        majorsNum.append(0)\n",
    "    majorsNum[majors.index(row['Major'])] += 1\n",
    "for i in range(len(majors) - 1):\n",
    "    print(majors[i + 1], majorsNum[i + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a98bb-2979-49d9-88bd-63690b57fc98",
   "metadata": {},
   "source": [
    "The most common customers are Chemistry majors, thenBiology and then Physics. It seems that students of science are the most likely to order at FoodX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "17b05cd9-251d-440f-ac2b-47ff3641c061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indiana State University 1309\n",
      "Ball State University 1085\n",
      "Butler University 1614\n",
      "Indiana University-Purdue University Indianapolis (IUPUI) 682\n",
      "University of Notre Dame 144\n",
      "University of Evansville 143\n",
      "Valparaiso University 9\n",
      "Purdue University 1\n",
      "Indiana University Bloomington 12\n",
      "DePauw University 1\n"
     ]
    }
   ],
   "source": [
    "file.seek(0)\n",
    "unis = []\n",
    "unisNum = []\n",
    "for row in data:\n",
    "    if not (row['University'] in unis):\n",
    "        unis.append(row['University'])\n",
    "        unisNum.append(0)\n",
    "    unisNum[unis.index(row['University'])] += 1\n",
    "for i in range(len(unis) - 1):\n",
    "    print(unis[i + 1], unisNum[i + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94fb4c2-ceeb-4041-bdc8-033178e6c240",
   "metadata": {},
   "source": [
    "FoodX is most popular with Butler University students, followed by IU students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "380f3d86-efb2-4826-bf6b-bcf4f00f1dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 8),\n",
       " (9, 40),\n",
       " (10, 247),\n",
       " (11, 857),\n",
       " (12, 1314),\n",
       " (13, 1316),\n",
       " (14, 883),\n",
       " (15, 282),\n",
       " (16, 49),\n",
       " (17, 4)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.seek(0)\n",
    "time = []\n",
    "timeNum = []\n",
    "for row in data:\n",
    "    if not (row['Time'] in time):\n",
    "        time.append(row['Time'])\n",
    "        timeNum.append(0)\n",
    "    timeNum[time.index(row['Time'])] += 1\n",
    "time = time[1:]\n",
    "timeNum = timeNum[1:]\n",
    "for i in range(len(time)):\n",
    "    time[i] = int(time[i])\n",
    "timeZip = sorted(zip(time, timeNum))\n",
    "timeZip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a75c98e-feaa-4eae-b86e-c898df4c7942",
   "metadata": {},
   "source": [
    "11-14 is the most popular time of day to get food. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0e9bcf54-36a7-40f6-897c-f190197051f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fried Catfish Basket 490\n",
      "Sugar Cream Pie 512\n",
      "Indiana Pork Chili 510\n",
      "Indiana Corn on the Cob (brushed with garlic butter) 495\n",
      "Indiana Buffalo Chicken Tacos (3 tacos) 496\n",
      "Sweet Potato Fries 508\n",
      "Ultimate Grilled Cheese Sandwich (with bacon and tomato) 503\n",
      "Breaded Pork Tenderloin Sandwich 494\n",
      "Cornbread Hush Puppies 510\n",
      "Hoosier BBQ Pulled Pork Sandwich 482\n"
     ]
    }
   ],
   "source": [
    "file.seek(0)\n",
    "orders = []\n",
    "ordersNum = []\n",
    "for row in data:\n",
    "    if not (row['Order'] in orders):\n",
    "        orders.append(row['Order'])\n",
    "        ordersNum.append(0)\n",
    "    ordersNum[orders.index(row['Order'])] += 1\n",
    "for i in range(len(orders) - 1):\n",
    "    print(orders[i + 1], ordersNum[i + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3017a6-5fd0-46fe-b9bb-dd87311c7cd1",
   "metadata": {},
   "source": [
    "The most popular item on the menu is Sugar Cream Pie. This might imply that students are looking for a quick sweet snack from FoodX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "cf32ed93-77b3-4978-80ee-fadf1ee2383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4baaf-8e8c-40aa-b10b-2ee9d8f974e7",
   "metadata": {},
   "source": [
    "### Consider implications of data collection, storage, and data biases you would consider relevant here considering Data Ethics, Business Outcomes, and Technical Implications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2156c7c-28db-40b0-896f-6d43ae64fb67",
   "metadata": {},
   "source": [
    "Ethically as long as the data is held securely and the names and identities of the students using the app are not disclosed within the data there are few ethical concerns. The data does not discriminate based on identity and simply reports the student's academic major, year and order details. \n",
    "\n",
    "Through analyzing the data we can see a few Business implications. There is most likely no easily available FoodX truck in Purdue, IU Bloomington, DePauw, and Valparaiso. I make this prediction because there there are less than 12 orders from students of these universities. The overwhelming majority of orders occur between 11-14. If the costs outweigh the profits it could be prudent to reduce the amount of hours the food truck operates. Especially at 17 and onwards the amount of orders is tiny. The most popular item on the menu is a Sugar Cream Pie, this is the only desert item on the menu and it might improve sales to include more sugary items. \n",
    "\n",
    "There is little to no data on the preferences of 1st years and 2nd years. Most likely the NN will be much more innacurate for 1st year or 4th years students. A similar problem arises with students of the 4 universities outlined above which had few responses. I believe time of day and major are going to be the major indicators of preference, students most likely buy heavier meals during lunch time and lighter snacks at odd hours. The Neural network will have 10 input neurons to represent the University of the student, 10 input neurons for the Major, a single neuron between 0 and 1 that represents the time of day, and 4 neurons to represent year. This makes a total of 35 input neurons. There shall also be 10 ouput neurons for each food item. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f84028-a76b-4888-a235-9327bdce0096",
   "metadata": {},
   "source": [
    "### Build a model to predict a customers order from their available information.  You will be graded largely on your intent and process when designing the model, performance is secondary. It is strongly suggested that you use SKLearn for this model as to not take too much time.  You may use any kind implementation you would like though, but it must be pickelable and have a “.predict()” method similar to SKLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a27618-a975-4c3c-932f-0e9366e6c596",
   "metadata": {},
   "source": [
    "Building the Neural Network I will be using tensorflow, as it is the library I am most familiar with. I created two simple functions that extract the x and y values from the CSV file. After analyzing the data I have determined that the best way to categorize the x and y is as follows. The x will be 35 input neurons. 4 Neurons to represent the Year of the customer, 10 to reperesent their University, 20 to represent their major and a single Neuron to represent the time they ordered from FoodX. I made this choice because while Year, University, and Major are discrete choices that the student has made the time of order lies on a spectrum and as such would be better represented through a single neuron.\n",
    "\n",
    "The output is 10 neurons representing the 10 different orders that the student could make. 1 represents the Order that was actually ordered, all of the other orders will be 0. When fitting the program the loss function has been set to Logits=True, as such it will treat the output as probablities that the program believes one specific choice is the correct one over another. The highest number will be treated as the Network's choice and will be used to determine the accuracy. After this I have split the x and y set into training and testing data which consist of entirely sepparate cases. I will be testing the accuracy of the Neural network on the test data after the training is complete to account for overfitting. I have also included a Dropout layer within the neural network to reduce overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "8ec98d44-f016-40cb-b7d2-d4d38676a627",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(fileName):\n",
    "    x = []\n",
    "    file = open(fileName)\n",
    "    data = csv.DictReader(file)\n",
    "    next(data)\n",
    "    for row in data:\n",
    "        year = row['Year']\n",
    "        match year:\n",
    "            case \"Year 1\":\n",
    "                year = [1, 0, 0, 0]\n",
    "            case \"Year 2\":\n",
    "                year = [0, 1, 0, 0]\n",
    "            case \"Year 3\":\n",
    "                year = [0, 0, 1, 0]\n",
    "            case \"Year 4\":\n",
    "                year = [0, 0, 0, 1]\n",
    "        major = row['Major']\n",
    "        match major:\n",
    "            case \"Physics\":\n",
    "                major = [0] * 20\n",
    "                major[0] += 1\n",
    "            case \"Chemistry\":\n",
    "                major = [0] * 20\n",
    "                major[1] += 1\n",
    "            case \"Biology\":\n",
    "                major = [0] * 20\n",
    "                major[2] += 1\n",
    "            case \"Business Administration\":\n",
    "                major = [0] * 20\n",
    "                major[3] += 1\n",
    "            case \"Anthropology\":\n",
    "                major = [0] * 20\n",
    "                major[4] += 1\n",
    "            case \"Mathematics\":\n",
    "                major = [0] * 20\n",
    "                major[5] += 1\n",
    "            case \"Economics\":\n",
    "                major = [0] * 20\n",
    "                major[6] += 1\n",
    "            case \"Astronomy\":\n",
    "                major = [0] * 20\n",
    "                major[7] += 1\n",
    "            case \"Marketing\":\n",
    "                major = [0] * 20\n",
    "                major[8] += 1\n",
    "            case \"Political Science\":\n",
    "                major = [0] * 20\n",
    "                major[9] += 1\n",
    "            case \"Finance\":\n",
    "                major = [0] * 20\n",
    "                major[10] += 1\n",
    "            case \"Sociology\":\n",
    "                major = [0] * 20\n",
    "                major[11] += 1\n",
    "            case \"Accounting\":\n",
    "                major = [0] * 20\n",
    "                major[12] += 1\n",
    "            case \"Psychology\":\n",
    "                major = [0] * 20\n",
    "                major[13] += 1\n",
    "            case \"International Business\":\n",
    "                major = [0] * 20\n",
    "                major[14] += 1\n",
    "            case \"Music\":\n",
    "                major = [0] * 20\n",
    "                major[15] += 1\n",
    "            case \"Mechanical Engineering\":\n",
    "                major = [0] * 20\n",
    "                major[16] += 1\n",
    "            case \"Philosophy\":\n",
    "                major = [0] * 20\n",
    "                major[17] += 1\n",
    "            case \"Fine Arts\":\n",
    "                major = [0] * 20\n",
    "                major[18] += 1\n",
    "            case \"Civil Engineering\":\n",
    "                major = [0] * 20\n",
    "                major[19] += 1\n",
    "        university = row['University']\n",
    "        match university:\n",
    "            case \"Indiana State University\":\n",
    "                university = [0] * 10\n",
    "                university[0] += 1\n",
    "            case \"Ball State University\":\n",
    "                university = [0] * 10\n",
    "                university[1] += 1\n",
    "            case \"Butler University\":\n",
    "                university = [0] * 10\n",
    "                university[2] += 1\n",
    "            case \"Indiana University-Purdue University Indianapolis (IUPUI)\":\n",
    "                university = [0] * 10\n",
    "                university[3] += 1\n",
    "            case \"University of Notre Dame\":\n",
    "                university = [0] * 10\n",
    "                university[4] += 1\n",
    "            case \"University of Evansville\":\n",
    "                university = [0] * 10\n",
    "                university[5] += 1\n",
    "            case \"Valparaiso University\":\n",
    "                university = [0] * 10\n",
    "                university[6] += 1\n",
    "            case \"Purdue University\":\n",
    "                university = [0] * 10\n",
    "                university[7] += 1\n",
    "            case \"Indiana University Bloomington\":\n",
    "                university = [0] * 10\n",
    "                university[8] += 1\n",
    "            case \"DePauw University\":\n",
    "                university = [0] * 10\n",
    "                university[9] += 1\n",
    "        time = int(row['Time'])\n",
    "        time /= 24\n",
    "        time = [time]\n",
    "        x.append(numpy.array(year + major + university + time))\n",
    "    x = numpy.array(x)\n",
    "    file.close()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "987d70cb-a257-49a0-b71a-0a3265879d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(fileName):\n",
    "    y = []\n",
    "    file = open(fileName)\n",
    "    data = csv.DictReader(file)\n",
    "    next(data)\n",
    "    for row in data:\n",
    "        order = [0] * 10\n",
    "        match row['Order']:\n",
    "            case \"Fried Catfish Basket\":\n",
    "                order[0] += 1\n",
    "            case \"Sugar Cream Pie\":\n",
    "                order[1] += 1\n",
    "            case \"Indiana Pork Chili\":\n",
    "                order[2] += 1\n",
    "            case \"Indiana Corn on the Cob (brushed with garlic butter)\":\n",
    "                order[3] += 1\n",
    "            case \"Indiana Buffalo Chicken Tacos (3 tacos)\":\n",
    "                order[4] += 1\n",
    "            case \"Sweet Potato Fries\":\n",
    "                order[5] += 1\n",
    "            case \"Ultimate Grilled Cheese Sandwich (with bacon and tomato)\":\n",
    "                order[6] += 1\n",
    "            case \"Breaded Pork Tenderloin Sandwich\":\n",
    "                order[7] += 1\n",
    "            case \"Cornbread Hush Puppies\":\n",
    "                order[8] += 1\n",
    "            case \"Hoosier BBQ Pulled Pork Sandwich\":\n",
    "                order[9] += 1\n",
    "        y.append(numpy.array(order))\n",
    "    y = numpy.array(y)\n",
    "    file.close()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c7b4c3c7-fedd-4c4f-a510-c68c1e771af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_x('XTern 2024 Artificial Intelegence Data Set - Xtern_TrainData.csv')\n",
    "y = get_y('XTern 2024 Artificial Intelegence Data Set - Xtern_TrainData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "071d22a1-14e0-4a05-94b5-42cbb8af467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[int(len(x) / 2):]\n",
    "x_test = x[:int(len(x) / 2)]\n",
    "y_train = y[int(len(y) / 2):]\n",
    "y_test = y[:int(len(y) / 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "186113ba-9913-447a-936d-c7d5a5b30169",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(35),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.08),\n",
    "        tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "97020bb3-24c0-463a-bd6c-f95862c74c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "53c8829f-40a8-45b3-b862-91689760e257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "79/79 [==============================] - 1s 2ms/step - loss: 1.9759 - accuracy: 0.3556\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.4961 - accuracy: 0.4848\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3996 - accuracy: 0.5008\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3576 - accuracy: 0.5100\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 1.3109 - accuracy: 0.5232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28abe6f8940>"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "fd203122-95a8-44c4-9325-a59dcea4dd72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 - 0s - loss: 1.3208 - accuracy: 0.5214 - 263ms/epoch - 3ms/step\n",
      "Test Accuracy: 0.5214085578918457\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"Test Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e468ad2-6823-4b34-8fd9-33cf35324594",
   "metadata": {},
   "source": [
    "### Given the work required to bring a solution like this to maturity and its performance, what considerations would you make to determine if this is a suitable course of action?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b590e7a-bcd7-4a5e-8b7f-c62d554bbd35",
   "metadata": {},
   "source": [
    "Currently the system is performing at 52% accuracy for guessing between 10 possible orders. This is quite good compared to random chance, however if the company is losing 10% of the revenue on every order it guesses incorrectly I do not believe the system with the current accuracy is acceptable. More data and a larger Neural Network would be required to guess orders with better than 75% accuracy. With the current metrics measured I do not believe it is reasonable to hope for a significantly more precise system. Perhaps if the NN was trained on specific user's demographics and previous orders it would be more accurate. Knowing the age, race, interests, and past orders and time ordered of the student would be very helpful in determining their future orders. Currently however it would most likely lose the company more money than acceptable. The idea either needs to be abbandoned or much more user data needs to be scraped from data brokers or their activity on the app. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
